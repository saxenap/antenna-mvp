{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n",
    "import logging\n",
    "import numpy as np, pandas as pd\n",
    "import config, rules\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = pd.read_csv(config.files['service_rules'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupedDataRegex:\n",
    "    \n",
    "    def __init__(\n",
    "        self, joiner = '|'\n",
    "    ):\n",
    "        self.concat_char = joiner\n",
    "        \n",
    "    def make(self, groupby):\n",
    "        return groupby.apply(\n",
    "            lambda t: self.concat_char.join([str(i) for i in t])\n",
    "        ).astype(str)\n",
    "\n",
    "class GroupedDataRegexDecorator:\n",
    "    \n",
    "    def __init__(\n",
    "        self, regexer, param, prefix, suffix\n",
    "    ):\n",
    "        self.regexer = regexer\n",
    "        self.param = param\n",
    "        self.prefix = prefix\n",
    "        self.suffix = suffix\n",
    "        \n",
    "    def getType(self):\n",
    "        return self.param\n",
    "    \n",
    "    def make(self, groupby):\n",
    "        return (\n",
    "            self.prefix\n",
    "            + self.regexer.make(groupby)\n",
    "            + self.suffix\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'^(CBS |CFS|Lim Commercials 3mo|CBS - Fake Cancel|CBS All Access|Commercial Free 1 Week|CBS - Fake New|CBS All Access|CBS - Fake Cancel|Cancellation Confirmation CBS|CBS - Fake Cancel Passive Churn)$': 'CBS '\n",
      "                                                                                                                                                                                                           'All '\n",
      "                                                                                                                                                                                                           'Access',\n",
      " '^(Netflix|Basic (Netflix)|Premium (Netflix)|Standard (Netflix)|Netflix - Fake Cancel Passive Churn|Netflix)$': 'Netflix',\n",
      " '^(SHOWTIME|SHOWTIME - Fake New|SHOWTIME|Showtime Subscription|Cancellation Confirmation SHOWTIME|SHOWTIME - Fake Cancel|SHOWTIME - Fake Cancel|CBS All Access and Showtime|Showtime 1 month free trial|Showtime|SHOWTIME - Fake New|SHOWTIME - Fake Cancel)$': 'Showtime',\n",
      " '^(STARZ|STARZ|com.starz.starzplay.subscriptions|STARZ - Fake Cancel|STARZ|STARZ - Fake New|STARZ - Fake Cancel Passive Churn|STARZ - Fake New|STARZ - Fake Cancel)$': 'Starz',\n",
      " '^(hulu|Hulu|Renewable Subscription iOS|Disney Bundle: Disney+, Hulu, and ESPN+|Renewable Subscription Apple TV|Hulu|Hulu - Fake New current subscriber)$': 'Hulu',\n",
      " '^.*((Netflix)|Netflix).*$': 'Netflix',\n",
      " '^.*(CBS|CBS|All Access|CBS).*$': 'CBS All Access',\n",
      " '^.*(Disney bundle subscription has been canceled).*$': 'Hulu',\n",
      " '^.*(SHOWTIME|Showtime|Showtime|Showtime|SHOWTIME|Showtime|SHOWTIME|SHOW|SHOWTIME|SHOWTIME|Showtime 1 week free trial|SHOWTIME).*$': 'Showtime',\n",
      " '^.*(STARZ|STARZ|STARZ|Starz|STARZ|STARZ|STARZ).*$': 'Starz'}\n"
     ]
    }
   ],
   "source": [
    "matchers = []\n",
    "regexer = GroupedDataRegex('|')\n",
    "\n",
    "rdecorator = matchers.append(GroupedDataRegexDecorator(regexer, 'M', '(', ')'))\n",
    "sdecorator = matchers.append(GroupedDataRegexDecorator(regexer, 'S', '^(', ')$'))\n",
    "adecorator = matchers.append(GroupedDataRegexDecorator(regexer, 'A', '^.*(', ').*$'))\n",
    "\n",
    "copydd = rules[(rules['text_match'].notna())]\n",
    "\n",
    "regexes = {}\n",
    "for matcher in matchers:\n",
    "    type = copydd['matching']\n",
    "    regex = copydd[copydd['matching'] == matcher.getType()][['service_name','text_match']]\n",
    "    regex = matcher.make(regex.groupby('service_name')['text_match']).to_dict()\n",
    "    inv_map = {v: k for k, v in regex.items()}\n",
    "    regexes = {**regexes, **inv_map}\n",
    "    \n",
    "\n",
    "output(regexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
